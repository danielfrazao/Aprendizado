# -*- coding: utf-8 -*-
"""Aprendizado_T03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12HbEmN7gLpqxTyMaSAWbtU9nQDYR_g-Y
"""

#Disciplina : Aprendizado de máquina - Naive Bayes
#Aluno : Daniel Frazão Luiz
#Matrícula: 3200022

import pandas as pd
import numpy as np
from scipy import stats
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_excel('measXspecies.xls')

data.columns = ['sepal_length', 'sepal_width' , 'petal_length', 'petal_width', 'species']

#dividindo os grupos para pegar algumas informações gerais
data_setosa = data[(data.species == 'setosa')]
data_versicolor = data[(data.species == 'versicolor')]
data_virginica = data[(data.species == 'virginica')]

#Desvio padrão
data.groupby('species').std()

#Média
data.groupby('species').mean()

x0 = data_setosa['sepal_length']
sns.kdeplot(x0,label="Setosa", shade=True);
x1 = data_versicolor['sepal_length']
sns.kdeplot(x1,label="Versicolor", shade=True);
x2 = data_virginica['sepal_length']
sns.kdeplot(x2,label="Virginica", shade=True );

plt.xlabel('Distribuição do comprimento da sépala', fontsize=18)

x0 = data_setosa['sepal_width']
sns.kdeplot(x0,label="Setosa", shade=True);
x1 = data_versicolor['sepal_width']
sns.kdeplot(x1,label="Versicolor", shade=True);
x2 = data_virginica['sepal_width']
sns.kdeplot(x2,label="Virginica", shade=True );

plt.xlabel('Distribuição da largura da sépala', fontsize=18)

x0 = data_setosa['petal_length']
sns.kdeplot(x0,label="Setosa", shade=True);
x1 = data_versicolor['petal_length']
sns.kdeplot(x1,label="Versicolor", shade=True);
x2 = data_virginica['petal_length']
sns.kdeplot(x2,label="Virginica", shade=True );

plt.xlabel('Distribuição do comprimento da pétala', fontsize=18)

x0 = data_setosa['petal_width']
sns.kdeplot(x0,label="Setosa", shade=True);
x1 = data_versicolor['petal_width']
sns.kdeplot(x1,label="Versicolor", shade=True);
x2 = data_virginica['petal_width']
sns.kdeplot(x2,label="Virginica", shade=True );

plt.xlabel('Distribuição da largura da pétala', fontsize=18)

def plot_iris_score(iris, y_test, scores):
    '''Function to plot iris data by type'''
    ## Find correctly and incorrectly classified cases
    true = np.equal(scores, y_test).astype(int)
    
    ## Create data frame from the test data
    iris = pd.DataFrame(iris)
    levels = {0:'setosa', 1:'versicolor', 2:'virginica'}
    iris['Species'] = [levels[x] for x in y_test]
    iris.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']
    
    ## Set up for the plot
    fig, ax = plt.subplots(2, 2, figsize=(12,12))
    markers = ['o', '+']
    x_ax = ['Sepal_Length', 'Sepal_Width']
    y_ax = ['Petal_Length', 'Petal_Width']
    
    x_ax1 = ['Comprimento da sépala', 'Largura da sépala']
    y_ax2 = ['Largura da sépala', 'Largura da pétala']

    for t in range(2): # loop over correct and incorect classifications
        setosa = iris[(iris['Species'] == 'setosa') & (true == t)]
        versicolor = iris[(iris['Species'] == 'versicolor') & (true == t)]
        virginica = iris[(iris['Species'] == 'virginica') & (true == t)]
        # loop over all the dimensions
        for i in range(2):
            for j in range(2):
                ax[i,j].scatter(setosa[x_ax[i]], setosa[y_ax[j]], marker = markers[t], color = 'blue',)
                ax[i,j].scatter(versicolor[x_ax[i]], versicolor[y_ax[j]], marker = markers[t], color = 'orange')
                ax[i,j].scatter(virginica[x_ax[i]], virginica[y_ax[j]], marker = markers[t], color = 'green')
                ax[i,j].set_xlabel(x_ax1[i])
                ax[i,j].set_ylabel(y_ax2[j])

def print_metrics_3(labels, scores):
   
    conf = sklm.confusion_matrix(labels, scores)
    print('                 Confusion matrix')
    print('                 Score Setosa   Score Versicolor    Score Virginica')
    print('Actual Setosa      %6d' % conf[0,0] + '            %5d' % conf[0,1] + '             %5d' % conf[0,2])
    print('Actual Versicolor  %6d' % conf[1,0] + '            %5d' % conf[1,1] + '             %5d' % conf[1,2])
    print('Actual Vriginica   %6d' % conf[2,0] + '            %5d' % conf[2,1] + '             %5d' % conf[2,2])
    ## Now compute and display the accuracy and metrics
    print('')
    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))
    metrics = sklm.precision_recall_fscore_support(labels, scores)
    print(' ')
    print('          Setosa  Versicolor  Virginica')
    print('Num case   %0.2f' % metrics[3][0] + '     %0.2f' % metrics[3][1] + '      %0.2f' % metrics[3][2])
    print('Precision   %0.2f' % metrics[0][0] + '      %0.2f' % metrics[0][1] + '       %0.2f' % metrics[0][2])
    print('Recall      %0.2f' % metrics[1][0] + '      %0.2f' % metrics[1][1] + '       %0.2f' % metrics[1][2])
    print('F1          %0.2f' % metrics[2][0] + '      %0.2f' % metrics[2][1] + '       %0.2f' % metrics[2][2])

#Naive Bayes
from sklearn.naive_bayes import GaussianNB
from sklearn import preprocessing
import sklearn.metrics as sklm
import numpy.random as nr
import sklearn.model_selection as ms

Features = np.array(data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])
levels = {'setosa':0, 'versicolor':1, 'virginica':2}
Labels =  np.array([levels[x] for x in data['species']])

#Dividindo em 5 pastas, sendo quatro pra treino e uma pra teste

################# PASTA 1 #############################
nr.seed(1115)
indx = range(Features.shape[0])
indx = ms.train_test_split(indx, test_size = 30)
X_train = Features[indx[0],:]
y_train = np.ravel(Labels[indx[0]])
X_test = Features[indx[1],:]
y_test = np.ravel(Labels[indx[1]])

scale = preprocessing.StandardScaler()
scale.fit(X_train)
X_train = scale.transform(X_train)

NB_mod = GaussianNB()
NB_mod.fit(X_train, y_train)

X_test = scale.transform(X_test)
scores = NB_mod.predict(X_test)

print_metrics_3(y_test, scores)
conf = sklm.confusion_matrix(y_test, scores)
plot_iris_score(X_test, y_test, scores)

## Create data frame from the test data
iris = pd.DataFrame(X_test)
levels = {0:'setosa', 1:'versicolor', 2:'virginica'}
iris['Species'] = [levels[x] for x in y_test]
iris.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']

print("\nMédia:")
iris.groupby('Species').mean()
#######################################################

print("Desvio padrão")
iris.groupby('Species').std()

################# PASTA 2 #############################
nr.seed(113)
indx = range(Features.shape[0])
indx = ms.train_test_split(indx, test_size = 30)
X_train = Features[indx[0],:]
y_train = np.ravel(Labels[indx[0]])
X_test = Features[indx[1],:]
y_test = np.ravel(Labels[indx[1]])

scale = preprocessing.StandardScaler()
scale.fit(X_train)
X_train = scale.transform(X_train)

NB_mod = GaussianNB()
NB_mod.fit(X_train, y_train)

X_test = scale.transform(X_test)
scores = NB_mod.predict(X_test)

print_metrics_3(y_test, scores)
conf = sklm.confusion_matrix(y_test, scores)
plot_iris_score(X_test, y_test, scores)

## Create data frame from the test data
iris = pd.DataFrame(X_test)
levels = {0:'setosa', 1:'versicolor', 2:'virginica'}
iris['Species'] = [levels[x] for x in y_test]
iris.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']

print("\nMédia:")
iris.groupby('Species').mean()

########################################################

print("Desvio padrão")
iris.groupby('Species').std()

################# PASTA 3 #############################
nr.seed(2143)
indx = range(Features.shape[0])
indx = ms.train_test_split(indx, test_size = 30)
X_train = Features[indx[0],:]
y_train = np.ravel(Labels[indx[0]])
X_test = Features[indx[1],:]
y_test = np.ravel(Labels[indx[1]])

scale = preprocessing.StandardScaler()
scale.fit(X_train)
X_train = scale.transform(X_train)

NB_mod = GaussianNB()
NB_mod.fit(X_train, y_train)

X_test = scale.transform(X_test)
scores = NB_mod.predict(X_test)

print_metrics_3(y_test, scores)
conf = sklm.confusion_matrix(y_test, scores)
plot_iris_score(X_test, y_test, scores)

## Create data frame from the test data
iris = pd.DataFrame(X_test)
levels = {0:'setosa', 1:'versicolor', 2:'virginica'}
iris['Species'] = [levels[x] for x in y_test]
iris.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']

print("\nMédia:")
iris.groupby('Species').mean()
#######################################################

print("Desvio padrão")
iris.groupby('Species').std()

################# PASTA 4 #############################
nr.seed(117)
indx = range(Features.shape[0])
indx = ms.train_test_split(indx, test_size = 30)
X_train = Features[indx[0],:]
y_train = np.ravel(Labels[indx[0]])
X_test = Features[indx[1],:]
y_test = np.ravel(Labels[indx[1]])

scale = preprocessing.StandardScaler()
scale.fit(X_train)
X_train = scale.transform(X_train)

NB_mod = GaussianNB()
NB_mod.fit(X_train, y_train)

X_test = scale.transform(X_test)
scores = NB_mod.predict(X_test)

print_metrics_3(y_test, scores)
conf = sklm.confusion_matrix(y_test, scores)
plot_iris_score(X_test, y_test, scores)

## Create data frame from the test data
iris = pd.DataFrame(X_test)
levels = {0:'setosa', 1:'versicolor', 2:'virginica'}
iris['Species'] = [levels[x] for x in y_test]
iris.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']

print("\nMédia:")
iris.groupby('Species').mean()
#######################################################

print("Desvio padrão")
iris.groupby('Species').std()

################# PASTA 5 #############################
nr.seed(1123)
indx = range(Features.shape[0])
indx = ms.train_test_split(indx, test_size = 30)
X_train = Features[indx[0],:]
y_train = np.ravel(Labels[indx[0]])
X_test = Features[indx[1],:]
y_test = np.ravel(Labels[indx[1]])

scale = preprocessing.StandardScaler()
scale.fit(X_train)
X_train = scale.transform(X_train)

NB_mod = GaussianNB()
NB_mod.fit(X_train, y_train)

X_test = scale.transform(X_test)
scores = NB_mod.predict(X_test)

print_metrics_3(y_test, scores)
conf = sklm.confusion_matrix(y_test, scores)
plot_iris_score(X_test, y_test, scores)

## Create data frame from the test data
iris = pd.DataFrame(X_test)
levels = {0:'setosa', 1:'versicolor', 2:'virginica'}
iris['Species'] = [levels[x] for x in y_test]
iris.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']

print("\nMédia:")
iris.groupby('Species').mean()
#######################################################

print("Desvio padrão")
iris.groupby('Species').std()